{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4fa561b",
   "metadata": {},
   "source": [
    "# Kiến trúc light model (~1M tham số) cho CIFAR-10: MobileLite-C10\n",
    "\n",
    "Mục tiêu là một mô hình nhỏ gọn, khoảng 1 triệu tham số, nhưng vẫn đủ mạnh để phân loại ảnh CIFAR-10 (32×32).  \n",
    "\n",
    "## Ý tưởng chính\n",
    "- Dùng **Depthwise Separable Convolution (DS-Conv)** để giảm tham số.  \n",
    "- Khối cơ bản là **Inverted Residual Block** (còn gọi bottleneck).  \n",
    "- Kích hoạt dùng **ReLU6** (giúp phân phối gọn hơn khi lượng tử).  \n",
    "- Kết thúc bằng **Global Average Pooling (GAP)** thay vì fully-connected to.\n",
    "\n",
    "## Cấu trúc MobileLite-C10\n",
    "- **Stem**: Conv 3×3 (3→32α), stride=1, BN, ReLU6.  \n",
    "- **Stage 1**: 1× bottleneck (t=4, k=3, stride=1, out=24).  \n",
    "- **Stage 2**: 2× bottleneck (t=4, k=3, stride=2, out=32).  \n",
    "- **Stage 3**: 2× bottleneck (t=4, k=3, stride=2, out=48).  \n",
    "- **Stage 4**: 2× bottleneck (t=4, k=3, stride=1, out=64).  \n",
    "- **Stage 5**: Conv 1×1 (64→128α), BN, ReLU6.  \n",
    "- **Head**: GAP → FC (128α→10).  \n",
    "\n",
    "Ở đây α là hệ số \"width multiplier\". Với α=0.75, mô hình khoảng 0.9–1.1M tham số.  \n",
    "\n",
    "## Inverted Residual Block (bottleneck, t=4, k=3)\n",
    "1. **Expand**: PW conv 1×1 mở rộng số kênh: $C_{mid} = t \\cdot C_{in}$.  \n",
    "2. **Depthwise conv**: DW conv 3×3 trên từng kênh (stride 1 hoặc 2).  \n",
    "3. **Project**: PW conv 1×1 thu nhỏ về $C_{out}$.  \n",
    "4. Nếu stride=1 và $C_{in}=C_{out}$ thì cộng residual.\n",
    "\n",
    "Công thức block:\n",
    "\n",
    "$$\n",
    "Y =\n",
    "\\begin{cases}\n",
    "X + \\text{BN}(W_p * \\phi(\\text{BN}(W_d \\odot \\phi(\\text{BN}(W_e * X))))) & \\text{nếu stride=1, } C_{in}=C_{out} \\\\\n",
    "\\text{BN}(W_p * \\phi(\\text{BN}(W_d \\odot \\phi(\\text{BN}(W_e * X))))) & \\text{ngược lại}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Trong đó:\n",
    "- $W_e$: kernel 1×1 (expand).  \n",
    "- $W_d$: kernel depthwise 3×3.  \n",
    "- $W_p$: kernel 1×1 (project).  \n",
    "- $\\phi$: ReLU6.  \n",
    "- $\\odot$: convolution từng kênh (depthwise).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e056bcaf",
   "metadata": {},
   "source": [
    "# PTQ Phiên bản 1 — MinMax Calibration (chuẩn cơ bản)\n",
    "\n",
    "## Ý tưởng\n",
    "- Weights lượng tử **per-channel symmetric** (mỗi kênh có thang đo riêng, zero-point = 0).  \n",
    "- Activations lượng tử **per-tensor asymmetric** (toàn tensor chung scale, có zero-point).  \n",
    "- Calibration bằng min/max đơn giản, nhanh, dùng khoảng 512–1024 ảnh.\n",
    "\n",
    "## Công thức lượng tử\n",
    "- Quantize:  \n",
    "  $$\n",
    "  q = \\text{clip}\\left(\\left\\lfloor \\frac{x}{s} \\right\\rceil + z,\\ q_{min}, q_{max}\\right)\n",
    "  $$\n",
    "- Dequantize:  \n",
    "  $$\n",
    "  \\hat{x} = s \\cdot (q - z)\n",
    "  $$\n",
    "- Với activations (asymmetric):  \n",
    "  $$\n",
    "  s = \\frac{x_{max} - x_{min}}{q_{max} - q_{min}}, \\quad\n",
    "  z = \\left\\lfloor q_{min} - \\frac{x_{min}}{s} \\right\\rceil\n",
    "  $$\n",
    "- Với weights (symmetric, per-channel):  \n",
    "  $$\n",
    "  s_c = \\frac{\\max(|x_{min,c}|, |x_{max,c}|)}{127}, \\quad z_c = 0\n",
    "  $$\n",
    "\n",
    "## Trình tự\n",
    "1. Train mô hình FP32 → lưu checkpoint.  \n",
    "2. Fuse Conv–BN–ReLU.  \n",
    "3. Gắn observer (weights per-channel, activations per-tensor).  \n",
    "4. Chạy calibration (512–1024 ảnh không augment).  \n",
    "5. Convert sang INT8.  \n",
    "6. Đánh giá: accuracy, size, latency.  \n",
    "7. Nếu accuracy drop nhiều, tăng ảnh calibration hoặc dùng clipping 99.9%.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c6cbf6",
   "metadata": {},
   "source": [
    "# PTQ Phiên bản 2 — Histogram/KL Calibration + Bias Correction\n",
    "\n",
    "## Ý tưởng\n",
    "- MinMax dễ bị outlier. Thay vào đó, dùng histogram và chọn ngưỡng tối ưu bằng KL-divergence (hoặc MSE).  \n",
    "- Sau lượng tử, áp dụng **bias correction** để bù lại sai số trung bình.\n",
    "\n",
    "## Calibration bằng histogram + KL\n",
    "- Xây histogram $H$ của activation.  \n",
    "- Tìm ngưỡng $T$ để phân bố lượng tử $\\tilde{P}_T$ gần với phân bố gốc $P$:  \n",
    "  $$\n",
    "  T^\\star = \\arg\\min_T \\mathrm{KL}(P(\\cdot \\mid |x| \\le T)\\,\\|\\,\\tilde{P}_T)\n",
    "  $$\n",
    "- Sau đó scale: $s = T^\\star / q_{max}$ (nếu symmetric).\n",
    "\n",
    "## Bias correction\n",
    "- Với lớp conv: $y = W * x + b$.  \n",
    "- Sau lượng tử: $\\hat{y} = \\hat{W} * \\hat{x} + \\hat{b}$.  \n",
    "- Ước lượng sai lệch:  \n",
    "  $$\n",
    "  \\Delta_c = \\mathbb{E}_{\\mathcal{D}}[y_c - \\hat{y}_c]\n",
    "  $$\n",
    "- Cập nhật bias:  \n",
    "  $$\n",
    "  \\hat{b}_c \\leftarrow \\hat{b}_c + \\Delta_c\n",
    "  $$\n",
    "\n",
    "## Trình tự\n",
    "1. Train FP32, fuse Conv–BN–ReLU.  \n",
    "2. Chèn observer histogram cho activations.  \n",
    "3. Calibration (khoảng 1000 ảnh).  \n",
    "4. Tìm ngưỡng tối ưu theo KL hoặc MSE.  \n",
    "5. Convert sang INT8.  \n",
    "6. Chạy bias correction bằng calibration set.  \n",
    "7. Đánh giá lại.  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
