{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d49862df",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# I, Phương pháp "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1641437f",
   "metadata": {},
   "source": [
    "## Phương pháp 1: MnasNet\n",
    "\n",
    "**Ý tưởng:**  \n",
    "MnasNet sử dụng **Reinforcement Learning** với một **controller** sinh ra kiến trúc mạng con $ \\mathcal{A} $.  \n",
    "Mỗi kiến trúc được huấn luyện sơ bộ, đánh giá accuracy và đo **độ trễ thực tế (latency)** trên thiết bị di động.  \n",
    "Hàm thưởng $R(\\mathcal{A})$ kết hợp **độ chính xác** và **độ trễ**:\n",
    "\n",
    "- Controller sinh chuỗi hành động $ a_1, a_2, \\dots, a_T $ mô tả kiến trúc.\n",
    "- Huấn luyện mô hình tương ứng, thu được accuracy $ \\mathrm{ACC}(\\mathcal{A}) $ và độ trễ $ \\mathrm{LAT}(\\mathcal{A}) $.\n",
    "\n",
    "Hàm thưởng:\n",
    "\n",
    "$$\n",
    "R(\\mathcal{A}) = \\mathrm{ACC}(\\mathcal{A}) \\times \\big(\\mathrm{LAT}(\\mathcal{A})\\big)^\\beta\n",
    "$$\n",
    "\n",
    "với $\\beta < 0$ để phạt các mô hình chậm.  \n",
    "Controller được tối ưu bằng policy gradient:\n",
    "\n",
    "$$\n",
    "\\nabla_\\theta J(\\theta) = \\mathbb{E}_{\\mathcal{A}\\sim \\pi_\\theta} \\big[ R(\\mathcal{A}) \\, \\nabla_\\theta \\log \\pi_\\theta(\\mathcal{A}) \\big]\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c95cb18",
   "metadata": {},
   "source": [
    "## Phương pháp 2: MobileNetV3\n",
    "\n",
    "**Ý tưởng:**  \n",
    "MobileNetV3 được thiết kế bằng cách **dùng NAS (từ MnasNet) để xác định kiến trúc tổng thể**, sau đó **tinh chỉnh thủ công** để tối ưu thêm.  \n",
    "Cấu trúc mạng gồm các **Inverted Residual Blocks** kết hợp **Squeeze-and-Excitation (SE)** và **hàm kích hoạt h-swish**.\n",
    "\n",
    "- Inverted Residual block: giảm số kênh → depthwise conv → tăng số kênh\n",
    "- SE module: học trọng số kênh bằng cơ chế attention\n",
    "- Hàm h-swish:\n",
    "\n",
    "$$\n",
    "\\mathrm{h\\!-\\!swish}(x) = x \\cdot \\frac{\\mathrm{ReLU6}(x+3)}{6}\n",
    "$$\n",
    "\n",
    "MobileNetV3 có hai biến thể:\n",
    "- **Large:** tối ưu độ chính xác cao\n",
    "- **Small:** tối ưu độ trễ thấp cho thiết bị nhỏ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df02cd",
   "metadata": {},
   "source": [
    "## Phương pháp 3: Once-for-All (OFA)\n",
    "\n",
    "**Ý tưởng:**  \n",
    "Huấn luyện **một Supernet $ \\mathcal{N}_\\mathrm{super} $** chứa tất cả kiến trúc con khả dĩ, sau đó **rút trích (subnet)** phù hợp với từng giới hạn phần cứng mà không cần huấn luyện lại.  \n",
    "\n",
    "- Không gian tìm kiếm: $\\mathcal{S} = \\{\\text{depth}, \\text{width}, \\text{kernel size}, \\text{resolution}\\}$\n",
    "- Huấn luyện theo chiến lược **progressive shrinking**:\n",
    "  - Bắt đầu train mô hình lớn nhất\n",
    "  - Dần cho phép các subnet nhỏ hơn dùng chung trọng số\n",
    "\n",
    "Với một subnet $\\mathcal{A} \\in \\mathcal{S}$:\n",
    "\n",
    "$$\n",
    "\\theta_\\mathcal{A} \\subset \\theta_\\mathrm{super}\n",
    "$$\n",
    "\n",
    "và được đánh giá theo:\n",
    "\n",
    "$$\n",
    "\\max_{\\mathcal{A} \\in \\mathcal{S}} \\ \\mathrm{ACC}(\\mathcal{A}) \\quad \\text{s.t.} \\quad \\mathrm{LAT}(\\mathcal{A}) \\le L_\\mathrm{target}\n",
    "$$\n",
    "\n",
    "Nhờ weight sharing, tất cả subnet đều dùng chung trọng số đã huấn luyện từ Supernet.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055f8c37",
   "metadata": {},
   "source": [
    "## Phương pháp 4: TinyNAS\n",
    "\n",
    "**Ý tưởng:**  \n",
    "TinyNAS hướng tới thiết bị cực nhỏ (IoT), nên cần **NAS cực nhanh và hiệu quả**.  \n",
    "Nó sử dụng cách tiếp cận **predictor-based evolutionary search** với không gian kiến trúc đã được thu hẹp từ trước.\n",
    "\n",
    "- Không gian kiến trúc nhỏ: $\\mathcal{S} = \\{\\mathcal{A}_1, \\mathcal{A}_2, \\dots \\}$\n",
    "- Predictor $ f(\\mathcal{A}) $ ước lượng accuracy từ kiến trúc\n",
    "- Evolutionary search để chọn kiến trúc:\n",
    "\n",
    "$$\n",
    "\\mathcal{A}^* = \\arg\\max_{\\mathcal{A}\\in \\mathcal{S}} \\ f(\\mathcal{A}) \\quad \\text{s.t.} \\quad \\mathrm{LAT}(\\mathcal{A}) \\le L_\\mathrm{max}\n",
    "$$\n",
    "\n",
    "Predictor được huấn luyện bằng một tập nhỏ các kiến trúc đã train thật (data-efficient).  \n",
    "Sau đó chỉ train mô hình tốt nhất $ \\mathcal{A}^* $ từ đầu để dùng triển khai.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0652a1",
   "metadata": {},
   "source": [
    "# II, Đánh giá"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820c0980",
   "metadata": {},
   "source": [
    "- **Top-1 / Top-5 Accuracy**  \n",
    "  - Độ chính xác của mô hình trên tập kiểm tra.  \n",
    "  - **Top-1 Accuracy**: phần trăm mẫu có nhãn dự đoán đúng nhất khớp với nhãn thật.  \n",
    "  - **Top-5 Accuracy**: phần trăm mẫu có nhãn đúng nằm trong 5 dự đoán cao nhất.  \n",
    "\n",
    "- **Model Size (Params)**  \n",
    "  - Số lượng tham số học của mô hình (thường tính bằng triệu — M).  \n",
    "  - Chỉ số này ảnh hưởng trực tiếp đến khả năng deploy trên thiết bị giới hạn tài nguyên.\n",
    "\n",
    "- **FLOPs (Floating Point Operations)**  \n",
    "  - Số phép tính dấu phẩy động cần thực hiện để suy luận 1 ảnh đầu vào.  \n",
    "  - FLOPs thấp đồng nghĩa với tốc độ suy luận nhanh và tiết kiệm năng lượng.\n",
    "\n",
    "- **Inference Latency**  \n",
    "  - Thời gian mô hình cần để xử lý một ảnh đầu vào (ms).  \n",
    "  - Đo trên phần cứng mục tiêu như CPU di động hoặc GPU nhúng."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a09c1a73",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
